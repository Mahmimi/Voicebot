{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import time\n",
    "import networkx as nx\n",
    "import speech_recognition as sr\n",
    "import edge_tts\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    pipeline,\n",
    ")\n",
    "\n",
    "model_names = [\n",
    "    'wangchanberta-base-att-spm-uncased',\n",
    "]\n",
    "\n",
    "tokenizers = {\n",
    "    'wangchanberta-base-att-spm-uncased': AutoTokenizer,\n",
    "}\n",
    "public_models = ['xlm-roberta-base', 'bert-base-multilingual-cased']\n",
    "#Choose Pretrained Model\n",
    "model_name = \"wangchanberta-base-att-spm-uncased\" \n",
    "\n",
    "#create tokenizer\n",
    "tokenizer = tokenizers[model_name].from_pretrained(\n",
    "                f'airesearch/{model_name}' if model_name not in public_models else f'{model_name}',\n",
    "                revision='main',\n",
    "                model_max_length=416,)\n",
    "\n",
    "#pipeline\n",
    "zero_classify = pipeline(task='zero-shot-classification',\n",
    "         tokenizer=tokenizer,\n",
    "         model=AutoModelForSequenceClassification.from_pretrained(\n",
    "             f'airesearch/{model_name}' if model_name not in public_models else f'airesearch/{model_name}-finetuned',\n",
    "             revision='finetuned@xnli_th')\n",
    "         )\n",
    "\n",
    "def intent_classifier(text_input, candidate_labels, zero_classify=zero_classify):\n",
    "    output_label = zero_classify(text_input, candidate_labels=candidate_labels)\n",
    "    return output_label['labels'][0]\n",
    "\n",
    "customer_name = \"จิรานุวัฒน์\"\n",
    "bot_identity = 'female'\n",
    "bot_name = 'ท้องฟ้า'\n",
    "pronoun = 'ดิฉัน' if bot_identity == 'female' else 'กระผม'\n",
    "sentence_ending = ['ค่ะ','คะ'] if bot_identity == 'female' else ['ครับ','ครับ']\n",
    "comany_name = 'แมวเหมียว'\n",
    "\n",
    "# Create a directed graph\n",
    "A = nx.DiGraph(section='A')\n",
    "\n",
    "# Add nodes and edges\n",
    "A.add_node(\"START A\", response=f\"สวัสดี{sentence_ending[0]} ขอเรียนสายคุณ {customer_name}{sentence_ending[0]}\")\n",
    "A.add_node(\"A1\", response=f\"{pronoun} ต้องกราบขอประทานโทษเป็นอย่างสูงที่โทรมารบกวนนะ{sentence_ending[1]} {pronoun} ชื่อ {bot_name} ใบอนุญาตนายหน้าประกันวินาศภัยเลขที่ XXXXXXXXXX ติดต่อจากบริษัท {comany_name} จำกัด โทรมาเพื่อขออนุญาตนำเสนอสิทธิประโยชน์สำหรับลูกค้าของธนาคาร{comany_name} ไม่ทราบว่าจะสะดวกหรือไม่{sentence_ending[1]}\", intent_classify= lambda x :intent_classifier(x,[\"ได้\",\"ไม่ได้ ไม่ตกลง ยังไม่ตกลง ยังไม่ได้\"]))\n",
    "A.add_node(\"A2\", response=f\"{pronoun} ขออนุญาตติดต่อกลับคุณ{customer_name} อีกครั้งในวันที่....ไม่ทราบว่า คุณ{customer_name} สะดวกไหม{sentence_ending[1]} \")\n",
    "A.add_node(\"END\", response=f\"ต้องกราบขอประทานโทษเป็นอย่างสูงที่โทรมารบกวนนะ{sentence_ending[1]} {pronoun} หวังเป็นอย่างยิ่งว่าทางบริษัท {comany_name} จะได้ให้บริการคุณ{customer_name} ในโอกาสถัดไปนะ{sentence_ending[1]} หากคุณ{customer_name} ไม่ประสงค์ที่จะให้บริษัท {comany_name} ติดต่อเพื่อนำเสนอบริการของ บริษัท {comany_name} สามารถแจ้งผ่าน Call Center โทร 02-123-4567 ได้{sentence_ending[0]} ขอขอบพระคุณ ที่สละเวลาในการฟังข้อมูลของ บริษัท {comany_name} ขออนุญาตวางสาย{sentence_ending[0]} สวัสดี{sentence_ending[0]}\")\n",
    "A.add_node(\"A3\", response=f\"ขอบพระคุณ{sentence_ending[0]} และเพื่อเป็นการปรับปรุงคุณภาพในการให้บริการ ขออนุญาตบันทึกเสียงการสนทนาในครั้งนี้ด้วยนะ{sentence_ending[1]}\", intent_classify= lambda x :intent_classifier(x,[\"ได้\",\"ไม่ได้ ไม่ตกลง ยังไม่ตกลง ยังไม่ได้\"]))\n",
    "A.add_node(\"END A1\", response=f\"ขอบพระคุณ{sentence_ending[0]} ดิฉันจะไม่บันทึกเสียงการสนทนาในครั้งนี้{sentence_ending[0]}\")\n",
    "A.add_node(\"END A2\", response=f\"ขอบพระคุณ{sentence_ending[0]} ขณะนี้ได้เริ่มบันทึกการสนทนาแล้วนะ{sentence_ending[1]}\")\n",
    "\n",
    "A.add_edges_from(((\"START A\",\"A1\"),(\"A1\",\"A2\"),(\"A2\",\"END\"),(\"A1\",\"A3\"),(\"A3\",\"END A1\"),(\"A3\",\"END A2\")))\n",
    "\n",
    "# Create a directed graph\n",
    "B = nx.DiGraph(section='B')\n",
    "\n",
    "# Add nodes and edges\n",
    "B.add_node(\"START B\", response=f\"เนื่องในโอกาสที่ ธนาคาร{comany_name} ได้จัดตั้งบริษัท {comany_name} จำกัด เข้าเป็นบริษัทในกลุ่มธุรกิจการเงินของธนาคาร โดยมีวัตถุประสงค์ประกอบกิจการเป็นนายหน้าประกันวินาศภัย {pronoun} {bot_name} จึงติดต่อมาเพื่อขออนุญาตนำเสนอแผนประกันภัยรถยนต์แบบพิเศษเฉพาะลูกค้าของธนาคาร{comany_name}เท่านั้น {pronoun}ขอชี้แจงรายละเอียดนะ{sentence_ending[1]} \")\n",
    "B.add_node(\"B1\", response=f\"เพื่อให้ท่านสมาชิกได้รับประโยชน์สูงสุด จึงขออนุญาตสอบถามข้อมูลรถยนต์ของคุณ{customer_name} นะ{sentence_ending[1]}\")\n",
    "B.add_node(\"B2\", response=f\"รถยนต์มีประกันประเภทใด (1,2,3,2+,3+) รับประกันภัยโดยบริษัทฯใด สิ้นสุดความคุ้มครองเมื่อใด\")\n",
    "B.add_node(\"END B\", response=f\"{comany_name}ได้คัดสรรค์แบบประกัน เพื่อเป็นทางเลือกที่คุ้มค่าไว้บริการสำหรับลูกค้าของธนาคาร{comany_name} ดังนี้\")\n",
    "\n",
    "B.add_edges_from(((\"START B\",\"B1\"),(\"B1\",\"B2\"),(\"B2\",\"END B\")))\n",
    "\n",
    "Bot_dialog = nx.compose(A, B)\n",
    "Bot_dialog.add_edges_from(((\"END A1\",\"START B\"),(\"END A2\",\"START B\")))\n",
    "\n",
    "current_node = \"START A\"\n",
    "\n",
    "def addfile(filepath):\n",
    "    return filepath\n",
    "def submit_file(filepath):\n",
    "    return filepath\n",
    "def clear_audio():\n",
    "    return None\n",
    "def speech_to_text(audiofile_path):\n",
    "    recognizer = sr.Recognizer()\n",
    "\n",
    "    try:\n",
    "        with sr.WavFile(audiofile_path) as source:\n",
    "            audio = recognizer.record(source)\n",
    "        transcription = recognizer.recognize_google(audio,language = \"th-TH\")\n",
    "        return transcription\n",
    "    except:\n",
    "        return \"Could not understand audio\"\n",
    "    \n",
    "#bot response\n",
    "current_node = \"START A\"\n",
    "def user(user_input, history):\n",
    "        global current_node, Bot_dialog\n",
    "        \n",
    "        next_nodes = list(Bot_dialog.successors(current_node))\n",
    "    \n",
    "        if next_nodes != []:\n",
    "            if \"intent_classify\"  in Bot_dialog.nodes[current_node]:\n",
    "                intent = Bot_dialog.nodes[current_node][\"intent_classify\"](user_input)\n",
    "\n",
    "            if len(next_nodes) == 1:\n",
    "                current_node = next_nodes[0]\n",
    "            else:\n",
    "                if intent == \"ไม่ได้ ไม่ตกลง ยังไม่ตกลง ยังไม่ได้\":\n",
    "                    current_node = next_nodes[0]\n",
    "                else:\n",
    "                    current_node = next_nodes[1]\n",
    "\n",
    "        return user_input, history + [[user_input, None]]\n",
    "        \n",
    "def bot(history):\n",
    "    global current_node, Bot_dialog\n",
    "    history[-1][1] = \"\"\n",
    "    bot_message = Bot_dialog.nodes[current_node][\"response\"]\n",
    "\n",
    "    if current_node == \"END B\" or current_node == \"END\":\n",
    "        bot_message += \"\"\"<span style=\"color:red\"> \\n**Conversation Endded** </span>\"\"\"\n",
    "\n",
    "    for character in bot_message:\n",
    "        history[-1][1] += character\n",
    "        time.sleep(0.01)\n",
    "        yield history\n",
    "\n",
    "async def text_to_speech(inputtext_history: list[str], filename: str = \"tts_temp.wav\"):\n",
    "    input_text = inputtext_history[-1][1]\n",
    "    communicate = edge_tts.Communicate(input_text, \"th-TH-PremwadeeNeural\")\n",
    "\n",
    "    with open(filename, \"wb\") as file:\n",
    "        async for chunk in communicate.stream():\n",
    "            if chunk[\"type\"] == \"audio\":\n",
    "                file.write(chunk[\"data\"])\n",
    "            elif chunk[\"type\"] == \"WordBoundary\":\n",
    "                pass\n",
    "    \n",
    "    return filename\n",
    "\n",
    "async def restart(history):\n",
    "    global current_node, Bot_dialog\n",
    "    current_node = \"START A\"\n",
    "    await text_to_speech([[None, Bot_dialog.nodes[\"START A\"][\"response\"]]])\n",
    "    return [history[0]], '', 'tts_temp.wav'\n",
    "\n",
    "# init first audio greeting\n",
    "await text_to_speech([[None, Bot_dialog.nodes[\"START A\"][\"response\"]]])\n",
    "\n",
    "def main():\n",
    "    # Create a Gradio interface\n",
    "    with gr.Blocks(title='Chatbot Demo') as demo:\n",
    "\n",
    "        chatbot = gr.Chatbot(\n",
    "            [[None, Bot_dialog.nodes[\"START A\"][\"response\"]]],\n",
    "            elem_id=\"chatbot\",\n",
    "            bubble_full_width=False,\n",
    "            avatar_images=('https://aui.atlassian.com/aui/9.3/docs/images/avatar-person.svg',\n",
    "                            'https://avatars.githubusercontent.com/u/51063788?s=200&v=4')\n",
    "        )\n",
    "\n",
    "        with gr.Row():\n",
    "            txt = gr.Textbox(\n",
    "                scale=3,\n",
    "                show_label=False,\n",
    "                placeholder=\"transcription is Here.\",\n",
    "                container=False,\n",
    "                interactive=True,\n",
    "            )\n",
    "            voice_btn = gr.Audio(sources=\"microphone\",type=\"filepath\", scale=4)\n",
    "            voicesubmit_btn = gr.Button(value=\"Submit Voice✔️\", scale=1,variant='primary')\n",
    "\n",
    "        with gr.Row():\n",
    "            sentence = gr.Textbox(visible=False)\n",
    "            audio = gr.Audio(\n",
    "                value=\"tts_temp.wav\",\n",
    "                label=\"Generated audio response\",\n",
    "                streaming=True,\n",
    "                autoplay=False,\n",
    "                interactive=False,\n",
    "                show_label=True,\n",
    "            )\n",
    "\n",
    "        restart_btn = gr.Button(value='Restart🔄')\n",
    "        gr.Markdown(\n",
    "                        \"\"\"\n",
    "                        <div style=\"text-align: center;\">\n",
    "                            <h1 style=\"font-weight: bold; font-size: 30px;\">Insurance Voicebot Demo</h1>\n",
    "                        </div>\n",
    "                        <div style=\"text-align: left;\">\n",
    "                            <p style=\"font-weight: bold; font-size: 20px;\"><strong>To try this demo follow these steps.</strong></p> \n",
    "                        </div>                  \n",
    "                        \"\"\"\n",
    "        )\n",
    "        gr.Markdown(\"\"\"\n",
    "                        - From **Audio** block, click **Record** button and speak something to the bot.\n",
    "                        - When finished recording, click **Stop** button.\n",
    "                        - Click **Submit Voice✔️** button.\n",
    "                        - Wait until bot generate text and audio response.  \n",
    "                        - From **Generated audio response** block, click play button to play bot's audio response.\n",
    "                        - Continue these steps until you want to restart.          \n",
    "                    \"\"\"\n",
    "        )\n",
    "\n",
    "        voice_btn.stop_recording(addfile, inputs=voice_btn, outputs=txt)\n",
    "        voicesubmit_btn.click(submit_file, inputs=voice_btn, outputs=txt).then(speech_to_text, inputs=voice_btn, outputs=txt).then(user, [txt, chatbot], [txt, chatbot], queue=False).then(bot, chatbot, chatbot).then(clear_audio, outputs=voice_btn).then(text_to_speech, inputs=chatbot, outputs=audio)\n",
    "        restart_btn.click(restart, chatbot, [chatbot,txt,audio])\n",
    "\n",
    "    demo.launch(debug=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
